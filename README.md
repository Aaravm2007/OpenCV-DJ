ğŸ§ Gesture-Controlled DJ Mixer
Control music using just your hands â€” no touch, no mouse, just motion.

This project lets you mix and modify a local song in real-time using hand gestures tracked through your webcam.
Built with OpenCV, MediaPipe, and Python, it uses your left and right hands to adjust bass, treble, volume, and speech clarity â€” and even apply live filters like echo or reverb based on hand rotation.

ğŸŒ€ Demo

ğŸ¥ Coming soon!
Once the project is running, your webcam feed will appear with live gesture overlays while the songâ€™s sound dynamically changes in response.

ğŸš€ Features
Feature	Description
ğŸ–ï¸ Dual-hand tracking	Detects and distinguishes left vs right hands in real time using MediaPipe
ğŸšï¸ Live audio control	Adjust bass, treble, volume, and speech clarity via hand movement
ğŸ”„ Rotation filters	Rotate left or right hand to toggle echo or reverb effects
ğŸ§  Intelligent smoothing	Gesture data is averaged over frames for stable control
ğŸµ Local file playback	Works with .mp3 or .wav songs stored on your computer
ğŸ’» Modular code	Clean separation between gesture detection, audio control, and main loop
ğŸ§  Gesture Mappings
Hand	Motion	Effect
âœ‹ Left hand â†‘	Increase Bass	
âœ‹ Left hand â†“	Decrease Bass	
âœ‹ Left hand â†’	Increase Treble	
âœ‹ Left hand â†	Decrease Treble	
ğŸ¤š Right hand â†‘	Increase Volume	
ğŸ¤š Right hand â†“	Decrease Volume	
ğŸ¤š Right hand â†’	Increase Speech Clarity (boost 1â€“3 kHz)	
ğŸ¤š Right hand â†	Decrease Speech Clarity	
â†» Left hand rotation	Toggle Echo filter	
â†» Right hand rotation	Toggle Reverb filter	
ğŸ—ï¸ Project Structure
gesture-dj-mixer/
â”‚
â”œâ”€â”€ main.py                # Main loop connecting camera and audio engine
â”œâ”€â”€ gesture_tracker.py     # Handles MediaPipe hand tracking and gesture recognition
â”œâ”€â”€ audio_controller.py    # Applies EQ, volume, and filters to the song
â”œâ”€â”€ requirements.txt       # All Python dependencies
â””â”€â”€ README.md              # Project documentation

âš™ï¸ Installation

Clone the repository

git clone https://github.com/yourusername/gesture-dj-mixer.git
cd gesture-dj-mixer


Install dependencies

pip install -r requirements.txt


or manually:

pip install opencv-python mediapipe numpy pydub scipy sounddevice


Add your song

Place a .mp3 or .wav file in the project directory.

Rename it to song.mp3 or update the filename in audio_controller.py.

Run the program

python main.py

ğŸ§© How It Works

Hand Tracking â€“ MediaPipe detects 21 landmarks per hand and distinguishes left vs right.

Gesture Recognition â€“ Movement and rotation deltas (Î”x, Î”y, angle) are analyzed each frame.

Action Mapping â€“ Each motion direction is mapped to a specific audio control (e.g., bassâ†‘).

Audio Processing â€“ The local song is continuously filtered using pydub and scipy.signal.

Feedback â€“ The camera window overlays the detected gestures and active filters live.

ğŸšï¸ Audio Controls

Bass & Treble: Adjusted by low-pass and high-pass filters.

Speech Clarity: Boosts mid frequencies around 1â€“3 kHz.

Volume: Overall gain control in decibels.

Echo / Reverb: Simple convolution filters triggered by hand rotation.

ğŸ§  Technical Notes

Movement smoothing via a moving average to reduce jitter.

Rotation thresholds (~15Â°) used to prevent false filter toggles.

Modular threading ensures continuous playback while processing video.

Can be extended to use sounddevice streaming for near-zero latency DSP.

ğŸ§© Example Console Output
Detected: Left hand â†‘ â†’ Bass +2
Detected: Right hand â†“ â†’ Volume -3
Active Filters: Echo [ON], Reverb [OFF]
Bass: +6 | Treble: +2 | Volume: -1 | Speech: +3

ğŸ› ï¸ Future Enhancements

 Real-time FFT visualization overlay

 Gesture calibration for individual users

 Multi-song playlist control

 Integration with Spotify for visual controls (no audio processing)

 Lighting / LED sync with music intensity

ğŸ§‘â€ğŸ’» Tech Stack
Layer	Tools
Hand Tracking	MediaPipe + OpenCV
Audio DSP	Pydub, Scipy
Playback	SoundDevice
Language	Python 3.10+
Platform	Cross-platform (Windows / macOS / Linux)
ğŸ’¡ Inspiration

Inspired by touchless interfaces and virtual DJ systems â€” built to reimagine how we interact with music using pure motion and creativity.

ğŸ“œ License

MIT License Â© 2025 [Your Name]
